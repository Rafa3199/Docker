01 - Inicio:

1. O que é Docker? O que é um Container?
Container: É uma maneira de guardar aplicações com todas as dependências necessárias e configurações. É um artefato portátil, de fácil compartilhamento. Pode ser facilmente transportado entre o time de Dev e o time de Ops.

Permite o processo de desenvolvimento e lançamento da aplicação ser mais eficiente.
Onde os containers ficam? Eles ficam num repositório de containers, podendo ser um repositório privado ou Público, a depender da empresa. 
Repositório Público: hub.docker.com;

O que muda com os Containers? Antes, o processo de Desenvolvimento de uma aplicação era feito de maneira tal que diferentes desenvolvedores, com diferentes tipos de máquinas, necessitavam baixar e instalar cada aplicativo usado no desenvolvimento em suas máquinas. O problema é que dependendo da máquina ou de diferentes versões dos aplicativos, por exemplo, isso poderia gerar problemas para os desenvolvedores.

Comandos, códigos, execuções, muita coisa varia de uma máquina para outra (Mac vs Linux), até mesmo de uma versão para outra, às vezes.

Com os Containers, não é mais necessário instalar nenhum dos serviços agregados aquele desenvolvimento diretamente na sua máquina, porque o Container é um sistema operacional próprio, que “empacota” todas as configurações necessárias para que aquele trabalho seja transportado facilmente entre uma máquina e outra, levando todas as aplicações e serviços necessárias para o desenvolvimento daquele trabalho.

Resumindo, o Docker transformou a maneira que as coisas eram desenvolvidas, por solucionar o problema de “transporte” dos serviços e aplicações agregadas ao trabalho de uma maneira rápida, prática e eficiente.

Alguns comandos e suas aplicações:
 	"docker images" - Lista as imagens disponíveis
	"docker ps" - Lista todos os containers ativos
	"docker ps -a" - Lista todos os containers
	"docker run (image)" - Cria um novo container com a imagem desejada
	"docker run -it (image)" - Cria um container no modo interativo
	"docker run -P" - Mapeia a porta e automaticamente conecta na porta do host
	"docker run -d (image)" - Cria um container no background, sem expor o passo a passo para criação daquele container
	"docker run -e (variável)" - "-e" é para exportar variáveis de determinada imagem
	"docker run --name (nome) -it (image) - Cria um container interativo com nomepersonalizado
	"docker exec" - Executa comandos nos containers
	"docker start/stop/restart (container)" - Comandos para containers já existentes
	"docker rm (container)" - Remove containers
	"docker rmi (image)" - Remove images

É possível mapear todo o passo a passo para subir um container:

	"docker inspect (image) - Mostra inforações sobre a imagem e quais arquivos ela vai
					  executar para funcionar corretamente
	"docker logs (container) - Mostra todo o log do container do seu inicio até o ponto atual

Rodamos o "docker inspect" para entender quais arquivos e comandos vão ser executados para o correto funcionamento do container. E "docker logs" para verificar passo a passo a ativação do container e assim conseguimos analisar em qual passo ou etapa possa ter dado um erro e saber o que exatamente corrigir.


02 - Bind Mounts x Volumes
Bind Mounts (mudanças em tempo real entre o container e a máquina do host):
	"docker -v (caminho da pasta destino):(caminho da pasta do container) (nome da imagem)" - Armazenar na máquina local do usuário, os dados do container que será criado

Exemplo prático de tudo isso que vimos até agora sobre o "docker run":
	"docker run --name vprodb -d -e MYSQL_ROOT_PASSWORD=senha123 -p 3030:3306 -v /home/ubuntu/vprodbdata:/var/lib/mysql mysql:5.7"

Para que o exemplo acima funcione precisamos ter feito alguns passos antes:
	- Criar a pasta de destino na máquina local
	- Inspecionar o caminho que os dados são criados no container
	- Inspecionar as portas disponíveis para a imagem
	- Verificar a necessidade de variáveis para o container funcoinar (documentação oficial da imagem no hub.docker.com)

Containers Volumes (Preservação dos dados):
O comando é basicamente o mesmo que o Bind Mounts, apenas uma pequena diferença:
	"docker run --name vprodb -d -e MYSQL_ROOT_PASSWORD=senha123 -p 3030:3306 -v mydbdata:/var/lib/mysql mysql:5.7"

Para que o exemplo acima funcione precisamos ter feito alguns passos antes:
	- Criar um volume com o comando "docker volume create (nome)
	- Mudar o comando para que ao invés do caminho da pasta, como era no Bind Mounts, ele ir para o Volume criado
	- É importante notar que o comando é o mesmo do Bind Mounts apenas por exemplo, não seria possível executar o mesmo comando com o mesmo nome associado e a mesma porta de destino.

Building Images:
Precisamos criar um "Dockerfile" para que ele receba as instruções para criação da nossa "image". O que vai conter nesse "Dockerfile"?!

	- FROM --> Imagem base (Ubuntu, MySQL...)
	- LABELS --> Adiciona metada para a imagem
	- RUN --> Se quisermos fazer mudanças, instalar um pacote, criar um diretório ou arquivo. Qualquer comando que se queira executar.
	- ADD/COPY --> Vai copiar ou adicionar um arquivo na sua imagem
	- CMD --> Executa binaries/commands no comando "docker run"
	- ENTRYPOINT --> Vai ter maior escala de prioridade. Permite configurar um container que irá rodar como executável.
	- VOLUME --> Cria um ponto de montagem e marca como um "holding" externo de volumes montados
	- EXPOSE --> Container vai atribuir uma porta específica no "docker run"
	- ENV --> Sets the environment variable
	- USER --> Sets the user namo (or UID)
	- WORKDIR --> Sets the working directory
	- ARG --> Defines a variable that users can pass at build-time
	- ONBUILD --> Adds to the image a trigger instruction to be executed at a later time

Documentação: https://docs.docker.com/engine/reference/builder/

Vamos ver tudo isso num exemplo (Projeto de Website):
	- Pegar um modelo de website no tooplate.com
		- Definir o template
		- Apertar "F12" para abrir o log
		- Ir na área de "Network" do log
		- Baixar o endereço da pasta .zip do site
	- Fazer uma pasta com o nome do projeto
	- Dentro da pastar usar o "wget" com o link do template para puxar as informações
	- Instalar o "unzip" caso não esteja instalado
	- Usar o "unzip" no arquivo .zip criado
	- No diretório criado, usar o seguinte comando:
		- tar czvf nano.tar.gz * (pesquisar sobre isso, ainda não entendi 100%)
		- mv nano.tar.gz ../
		- Isso vai gerar um arquivo "tarball" no diretório do projeto
	- Remova os arquivos não desejados, se quiser
	- Mova o "artifato" tarball para a pasta criada do .zip
	- Na pastar criada do .zip usar o comando "vim" para editar um arquivo que vamos chamar de "Dockerfile"
	- Utilizar as seguintes instruções:
"
FROM ubuntu:latest (exemplo)
LABEL "Author"="Rafael" (exemplo)
LABEL "Project"="nano" (exemplo)
ENV DEBIAN_FRONTEND=noninteractive
RUN apt update && apt install git -y (exemplo)
RUN apt install apache2 -y (exemplo)
CMD ["/usr/sbin/apache2ctl", "-D", "FOREGROUND"]
EXPOSE 80 (exemplo)
WORKDIR /var/www/html (exemplo)
VOLUME /var/log/apache2 (exemplo)
ADD nano.tar.gz /var/www/html (exemplo)
#COPY nano.tar.gz /var/www/html
"
Obs.: A diferença do comando COPY para o ADD é que o ADD vai "untar" o arquivo no local indicado, enquanto o COPY vai apenas jogar o arquivo lá.

	- Use o comando "docker build" para criar sua imagem:
		- "docker build -t nanoimg"
	- Você pode verificar sua imagem criada com o "docker images"
	- Agora crie o container da sua imagem
		- "docker run -d --name nanowebsite -p 9080:80 nanoimg
	- Agora você já pode verificar o website funcionando através do endereço:
		- IP:port

Como jogar essa imagem no hub.docker?

	- Crie uma imagem com o nome do seu usuário do hub.docker como pré-fixo:
		- "docker build -t rafa3199/nanoimg
	- Faça login no hub.docker atráves do comando "docker login"
	- Preencha seu usuário e senha
	- Suba a sua imagem para um repositório publico que será criado automaticamente no hub.docker
		- "docker push rafa3199/nanoimg
	- Abra os seus repositórios no Docker e verifique se foi criado corretamente
	- Limpe o seu ambiente e faça um teste para tentar puxar a sua imagem criada direto do seu repositório no hub.docker
		- docker run -d --name nanowebsite -p 9080:80 rafa3199/nanoimg

Aula 03 - Entendendo a diferença entre o CMD e ENTRYPOINT
São parecidos, mas executam funções diferentes. O CMD pode conter o comando e o argumento, enquanto o ENTRYPOINT só possui o comando. O que isso quer dizer?

Quer dizer que, dependendo da necessidade do usuário, na hora de criar uma imagem ele pode tanto usar apenas o CMD para determinar qual o comando e argumento a ser executado, como pode usar apenas o ENTRYPOINT para passar a determinar a argumento, ou usar os dois juntos para ter um argumento padrão, mas também poder sobrescrever o argumento padrão.

Exemplo:

CMD ["echo", "hello"] - Quando a imagem for criada e executada, vai printar na tela o "hello" todas as vezes.

ENTRYPOINT ["echo"] - No comando do "docker build" é preciso determinar o argumento, ou irá sempre imprimir uma linha vazia.
	- docker build -t printer:v1 hello <-- Vai imprimir "hello" na tela

ENTRYPOINT ["echo"] - Temos o comando que será executado
CMD ["hello"] - E o argumento padrão, que por estarmos também usando o ENTRYPOINT, podemos determinar o argumento que queremos.
	- docker build -t printer:v1 hi <-- Vai imprimir "hi" ou invés de "hello" na tela
Essa estrutura também é utilizada para dar prioridade ao comando a ser executado, pois o ENTRYPOINT tem prioridade 0 na hora da execução.

Aula 04 - Docker Compose
Docker Compose é uma ferramenta para rodar multi containers ao mesmo tempo. O principal ponto do Docker Compose é evitar erros humanos, quando estamos trabalhando com vários e vários containers ao mesmo tempo.

Outro beneficio é que o arquivo do Docker Compose vai ser parte do seu repositório, qualquer mudança que for feita, vai ser rastreada.

Criamos arquivos de serviços que desejamos utilizar e colocamos dentro de uma mesma pasta com o Dockerfile. Para conciliar tudo, criamos um arquivo de "docker-compose.yml"

Vamos entender mais afundo com o exercicio prático proposto no própio site de documentação do Docker:

	- Como dito anteriormente, se faz necessário a criação de uma pasta de destino para os arquivos que vão ser criados para o Docker Compose, então crie um diretório. De preferencia, dentro da pasta do usuário, para não se ter problemas de permissões.
	- Logo após, começamos a criar os arquivos

1º Arquivo: app.py
-----------------------------------------------------------------------------------------------
import time

import redis
from flask import Flask

app = Flask(__name__)
cache = redis.Redis(host='redis', port=6379)

def get_hit_count():
    retries = 5
    while True:
        try:
            return cache.incr('hits')
        except redis.exceptions.ConnectionError as exc:
            if retries == 0:
                raise exc
            retries -= 1
            time.sleep(0.5)

@app.route('/')
def hello():
    count = get_hit_count()
    return 'Hello World! I have been seen {} times.\n'.format(count)
-----------------------------------------------------------------------------------------------
Como mencionado anteriormente, criamos arquivos dos serviços que vamos querer usar no Docker Compose, e este exemplo vai utilizando um arquivo de Python.

2º Arquivo: requirements.txt
-----------------------------------------------------------------------------------------------
flask
redis
-----------------------------------------------------------------------------------------------
Esse arquivo é apenas para listar serviços que vão ser necessários para roda nosso código.

3º Arquivo: Dockerfile
-----------------------------------------------------------------------------------------------
# syntax=docker/dockerfile:1
FROM python:3.7-alpine
WORKDIR /code
ENV FLASK_APP=app.py
ENV FLASK_RUN_HOST=0.0.0.0
RUN apk add --no-cache gcc musl-dev linux-headers
COPY requirements.txt requirements.txt
RUN pip install -r requirements.txt
EXPOSE 5000
COPY . .
CMD ["flask", "run"]
-----------------------------------------------------------------------------------------------
Esse já conhecemos, é o arquivo padrão para criar uma imagem no Docker, que será usado para o Docker Compose da mesma maneira. Esse arquivo de Dockerfile está dizendo ao Docker para:
	1. Criar uma imagem iniciando com a imagem do Python 3.7
	2. Definir o diretório de trabalho para /code
	3. Definir o ambiente que será usado pelo comando "flask"
	4. Instalar o gcc e outras dependencias
	5. Copiar o arquivo "requirements.txt" e instalar a dependencia do Python
	6. Adicionar metadata a imagem para descrever que o container está na porta 5000
	7. Copiar a pasta atual - "." - no diretório de trabalho da imagem
	8. Definir o comando padrão para o container para "flask run"

4º Arquivo: docker-compose.yml
-----------------------------------------------------------------------------------------------
version: "3.9"
services:
  web:
    build: .
    ports:
      - "8000:5000"
  redis:
    image: "redis:alpine"
-----------------------------------------------------------------------------------------------
Esse arquivo define dois serviços: "web" e "redis".
O serviço "web" use a imagem feita pelo "Dockerfile" na pasta atual. Então, combina o container e a máquina do host para a porta de entrada "8000". Esse exemplo use a porta de padrão para o Flask Web Service, 5000.

O serviço "redis" usa a imagem pública do Redis, puxada do Docker Hub.

	- Por fim, execute o docker compose
		- Esteja no diretório de trabalho onde foram criados todos os arquivos e o arquivo do Docker Compose
		- Em seguida, execute o comando de execução:
			"docker compose up"
	- No caso de estar na AWS utilize o IP + porta definida para acesar o container criado